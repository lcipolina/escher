{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "def get_data_loader(data_dir= \"data\", batch_size=1, train = True):\n",
    "    \"\"\"\n",
    "    Define the way we compose the batch dataset including the augmentation for increasing the number of data\n",
    "    and return the augmented batch-dataset\n",
    "    :param data_dir: root directory where the either train or test dataset is\n",
    "    :param batch_size: size of the batch\n",
    "    :param train: true if current phase is training, else false\n",
    "    :return: augmented batch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # define how we augment the data for composing the batch-dataset in train and test step\n",
    "    transform = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize([128, 128]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
    "            transforms.RandomHorizontalFlip(), # Flip the data horizontally\n",
    "            #TODO if it is needed, add the random crop\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize([128, 128]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # ImageFloder with root directory and defined transformation methods for batch as well as data augmentation\n",
    "    data = torchvision.datasets.ImageFolder(root=data_dir, transform=transform['train'] if train else 'test')\n",
    "    print(len(data))\n",
    "    train_size = int(0.9* len(data))\n",
    "    test_size = len(data) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    return data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "data_loader, test_data_loader = get_data_loader()\n",
    "print(len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Discriminator(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (conv5): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (fc1): Linear(in_features=13924, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (fc3): Linear(in_features=8, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_feature_size = 118, batch_size = 1, devices = 1):\n",
    "        \n",
    "        super(Discriminator, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.devices = devices\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(128, affine=False)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(256, affine=False)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(512, affine=False)\n",
    "        self.conv5 = nn.Conv2d(512, 1, 3)\n",
    "        self.fc1 = nn.Linear(in_feature_size * in_feature_size , 64)\n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "        self.fc3 = nn.Linear(8, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(self.batch_size , -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\"\n",
    "net = Discriminator()\n",
    "net = nn.DataParallel(net, device_ids=[0, 1, 2])\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgradai\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.14 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fresh-morning-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/gradai/uncategorized\" target=\"_blank\">https://wandb.ai/gradai/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/gradai/uncategorized/runs/5ivgpvse\" target=\"_blank\">https://wandb.ai/gradai/uncategorized/runs/5ivgpvse</a><br/>\n",
       "                Run data is saved locally in <code>/home/niranjan/Research/Escher/wandb/run-20220411_194540-5ivgpvse</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     2/   10] loss: 1.34688342\n",
      "[1,     4/   10] loss: 1.28042191\n",
      "[1,     6/   10] loss: 1.23096341\n",
      "[1,     8/   10] loss: 1.29556310\n",
      "Asdf\n",
      "[2,     2/   10] loss: 1.21664989\n",
      "[2,     4/   10] loss: 1.40906978\n",
      "[2,     6/   10] loss: 1.21670103\n",
      "[2,     8/   10] loss: 1.06725046\n",
      "Asdf\n",
      "[3,     2/   10] loss: 0.95000488\n",
      "[3,     4/   10] loss: 0.89417273\n",
      "[3,     6/   10] loss: 0.77991596\n",
      "[3,     8/   10] loss: 0.56906950\n",
      "Asdf\n",
      "[4,     2/   10] loss: 0.75509337\n",
      "[4,     4/   10] loss: 0.88606182\n",
      "[4,     6/   10] loss: 0.95910832\n",
      "[4,     8/   10] loss: 0.59957427\n",
      "Asdf\n",
      "[5,     2/   10] loss: 0.63418394\n",
      "[5,     4/   10] loss: 0.89843658\n",
      "[5,     6/   10] loss: 0.95187071\n",
      "[5,     8/   10] loss: 1.02480689\n",
      "Asdf\n",
      "[6,     2/   10] loss: 1.15355724\n",
      "[6,     4/   10] loss: 0.59867199\n",
      "[6,     6/   10] loss: 0.77441412\n",
      "[6,     8/   10] loss: 0.82494447\n",
      "Asdf\n",
      "[7,     2/   10] loss: 0.91472188\n",
      "[7,     4/   10] loss: 0.90381186\n",
      "[7,     6/   10] loss: 0.62808198\n",
      "[7,     8/   10] loss: 0.80861896\n",
      "Asdf\n",
      "[8,     2/   10] loss: 0.41075289\n",
      "[8,     4/   10] loss: 0.77783118\n",
      "[8,     6/   10] loss: 0.74114805\n",
      "[8,     8/   10] loss: 0.82928187\n",
      "Asdf\n",
      "[9,     2/   10] loss: 0.69758230\n",
      "[9,     4/   10] loss: 0.63976660\n",
      "[9,     6/   10] loss: 0.55169889\n",
      "[9,     8/   10] loss: 0.75741887\n",
      "Asdf\n",
      "[10,     2/   10] loss: 0.42085164\n",
      "[10,     4/   10] loss: 0.76749533\n",
      "[10,     6/   10] loss: 0.38980506\n",
      "[10,     8/   10] loss: 0.66635200\n",
      "Asdf\n",
      "[11,     2/   10] loss: 0.54071361\n",
      "[11,     4/   10] loss: 0.49658732\n",
      "[11,     6/   10] loss: 0.89813903\n",
      "[11,     8/   10] loss: 1.10874239\n",
      "Asdf\n",
      "[12,     2/   10] loss: 0.78221300\n",
      "[12,     4/   10] loss: 0.70443535\n",
      "[12,     6/   10] loss: 0.66075373\n",
      "[12,     8/   10] loss: 0.57484221\n",
      "Asdf\n",
      "[13,     2/   10] loss: 0.52210082\n",
      "[13,     4/   10] loss: 0.72706020\n",
      "[13,     6/   10] loss: 0.41654725\n",
      "[13,     8/   10] loss: 0.61694288\n",
      "Asdf\n",
      "[14,     2/   10] loss: 0.40491767\n",
      "[14,     4/   10] loss: 0.73507583\n",
      "[14,     6/   10] loss: 0.57585649\n",
      "[14,     8/   10] loss: 0.46436448\n",
      "Asdf\n",
      "[15,     2/   10] loss: 0.49250373\n",
      "[15,     4/   10] loss: 0.71468395\n",
      "[15,     6/   10] loss: 0.35527432\n",
      "[15,     8/   10] loss: 0.54637811\n",
      "Asdf\n",
      "[16,     2/   10] loss: 0.47948386\n",
      "[16,     4/   10] loss: 0.64753498\n",
      "[16,     6/   10] loss: 0.68643743\n",
      "[16,     8/   10] loss: 0.36798434\n",
      "Asdf\n",
      "[17,     2/   10] loss: 0.60486895\n",
      "[17,     4/   10] loss: 0.67621709\n",
      "[17,     6/   10] loss: 0.36123696\n",
      "[17,     8/   10] loss: 0.42205751\n",
      "Asdf\n",
      "[18,     2/   10] loss: 0.70119479\n",
      "[18,     4/   10] loss: 0.41770833\n",
      "[18,     6/   10] loss: 0.53005511\n",
      "[18,     8/   10] loss: 0.70850936\n",
      "Asdf\n",
      "[19,     2/   10] loss: 0.59050834\n",
      "[19,     4/   10] loss: 0.33210281\n",
      "[19,     6/   10] loss: 0.59224355\n",
      "[19,     8/   10] loss: 0.53950651\n",
      "Asdf\n",
      "[20,     2/   10] loss: 0.32963601\n",
      "[20,     4/   10] loss: 0.33501502\n",
      "[20,     6/   10] loss: 0.33890022\n",
      "[20,     8/   10] loss: 0.42086589\n",
      "Asdf\n",
      "[21,     2/   10] loss: 0.44427392\n",
      "[21,     4/   10] loss: 0.40386850\n",
      "[21,     6/   10] loss: 0.50209682\n",
      "[21,     8/   10] loss: 0.36480132\n",
      "Asdf\n",
      "[22,     2/   10] loss: 0.49852343\n",
      "[22,     4/   10] loss: 0.30824800\n",
      "[22,     6/   10] loss: 0.31215765\n",
      "[22,     8/   10] loss: 0.31801681\n",
      "Asdf\n",
      "[23,     2/   10] loss: 0.34598337\n",
      "[23,     4/   10] loss: 0.23353093\n",
      "[23,     6/   10] loss: 0.46173434\n",
      "[23,     8/   10] loss: 0.43684953\n",
      "Asdf\n",
      "[24,     2/   10] loss: 0.34119368\n",
      "[24,     4/   10] loss: 0.53538987\n",
      "[24,     6/   10] loss: 0.33094433\n",
      "[24,     8/   10] loss: 0.14784647\n",
      "Asdf\n",
      "[25,     2/   10] loss: 0.54953467\n",
      "[25,     4/   10] loss: 0.68575618\n",
      "[25,     6/   10] loss: 0.42151783\n",
      "[25,     8/   10] loss: 0.52227177\n",
      "Asdf\n",
      "[26,     2/   10] loss: 0.43705992\n",
      "[26,     4/   10] loss: 0.23219242\n",
      "[26,     6/   10] loss: 0.50720174\n",
      "[26,     8/   10] loss: 0.29637056\n",
      "Asdf\n",
      "[27,     2/   10] loss: 0.50040171\n",
      "[27,     4/   10] loss: 0.29200684\n",
      "[27,     6/   10] loss: 0.38229825\n",
      "[27,     8/   10] loss: 0.31834384\n",
      "Asdf\n",
      "[28,     2/   10] loss: 0.11658940\n",
      "[28,     4/   10] loss: 0.36123919\n",
      "[28,     6/   10] loss: 0.16158844\n",
      "[28,     8/   10] loss: 0.37664536\n",
      "Asdf\n",
      "[29,     2/   10] loss: 0.49304980\n",
      "[29,     4/   10] loss: 0.21229977\n",
      "[29,     6/   10] loss: 0.24291019\n",
      "[29,     8/   10] loss: 0.24325473\n",
      "Asdf\n",
      "[30,     2/   10] loss: 0.23240363\n",
      "[30,     4/   10] loss: 0.18895215\n",
      "[30,     6/   10] loss: 0.09249739\n",
      "[30,     8/   10] loss: 0.17519179\n",
      "Asdf\n",
      "[31,     2/   10] loss: 0.18200970\n",
      "[31,     4/   10] loss: 0.10177664\n",
      "[31,     6/   10] loss: 0.06036122\n",
      "[31,     8/   10] loss: 0.15061463\n",
      "Asdf\n",
      "[32,     2/   10] loss: 0.19627106\n",
      "[32,     4/   10] loss: 0.14941512\n",
      "[32,     6/   10] loss: 0.10724381\n",
      "[32,     8/   10] loss: 0.15495848\n",
      "Asdf\n",
      "[33,     2/   10] loss: 0.04596372\n",
      "[33,     4/   10] loss: 0.03619908\n",
      "[33,     6/   10] loss: 0.16381838\n",
      "[33,     8/   10] loss: 0.12978026\n",
      "Asdf\n",
      "[34,     2/   10] loss: 0.47046046\n",
      "[34,     4/   10] loss: 0.25071891\n",
      "[34,     6/   10] loss: 0.41249424\n",
      "[34,     8/   10] loss: 0.21088862\n",
      "Asdf\n",
      "[35,     2/   10] loss: 0.18296162\n",
      "[35,     4/   10] loss: 0.21643247\n",
      "[35,     6/   10] loss: 0.05863039\n",
      "[35,     8/   10] loss: 0.33662686\n",
      "Asdf\n",
      "[36,     2/   10] loss: 0.25731126\n",
      "[36,     4/   10] loss: 0.13579901\n",
      "[36,     6/   10] loss: 0.13821588\n",
      "[36,     8/   10] loss: 0.17445833\n",
      "Asdf\n",
      "[37,     2/   10] loss: 0.21395897\n",
      "[37,     4/   10] loss: 0.13438475\n",
      "[37,     6/   10] loss: 0.17333785\n",
      "[37,     8/   10] loss: 0.08601087\n",
      "Asdf\n",
      "[38,     2/   10] loss: 0.17418014\n",
      "[38,     4/   10] loss: 0.07473931\n",
      "[38,     6/   10] loss: 0.06121239\n",
      "[38,     8/   10] loss: 0.61733441\n",
      "Asdf\n",
      "[39,     2/   10] loss: 0.20178382\n",
      "[39,     4/   10] loss: 0.08104706\n",
      "[39,     6/   10] loss: 0.09041068\n",
      "[39,     8/   10] loss: 0.11561419\n",
      "Asdf\n",
      "[40,     2/   10] loss: 0.07306042\n",
      "[40,     4/   10] loss: 0.05815901\n",
      "[40,     6/   10] loss: 0.06990460\n",
      "[40,     8/   10] loss: 0.01521914\n",
      "Asdf\n",
      "[41,     2/   10] loss: 0.08553688\n",
      "[41,     4/   10] loss: 0.05128779\n",
      "[41,     6/   10] loss: 0.03413618\n",
      "[41,     8/   10] loss: 0.07205498\n",
      "Asdf\n",
      "[42,     2/   10] loss: 0.02838834\n",
      "[42,     4/   10] loss: 0.01774493\n",
      "[42,     6/   10] loss: 0.05467692\n",
      "[42,     8/   10] loss: 0.02532611\n",
      "Asdf\n",
      "[43,     2/   10] loss: 0.14938019\n",
      "[43,     4/   10] loss: 0.02392647\n",
      "[43,     6/   10] loss: 0.02394552\n",
      "[43,     8/   10] loss: 0.03446975\n",
      "Asdf\n",
      "[44,     2/   10] loss: 0.01879587\n",
      "[44,     4/   10] loss: 0.02040128\n",
      "[44,     6/   10] loss: 0.00501991\n",
      "[44,     8/   10] loss: 0.00511916\n",
      "Asdf\n",
      "[45,     2/   10] loss: 0.01261839\n",
      "[45,     4/   10] loss: 0.16121351\n",
      "[45,     6/   10] loss: 0.00588206\n",
      "[45,     8/   10] loss: 0.01130423\n",
      "Asdf\n",
      "[46,     2/   10] loss: 0.06503094\n",
      "[46,     4/   10] loss: 0.12800421\n",
      "[46,     6/   10] loss: 0.00912049\n",
      "[46,     8/   10] loss: 0.00488303\n",
      "Asdf\n",
      "[47,     2/   10] loss: 0.03263690\n",
      "[47,     4/   10] loss: 0.02397375\n",
      "[47,     6/   10] loss: 0.01106118\n",
      "[47,     8/   10] loss: 0.00773304\n",
      "Asdf\n",
      "[48,     2/   10] loss: 0.00673223\n",
      "[48,     4/   10] loss: 0.01438495\n",
      "[48,     6/   10] loss: 0.14350381\n",
      "[48,     8/   10] loss: 0.09734704\n",
      "Asdf\n",
      "[49,     2/   10] loss: 0.07478011\n",
      "[49,     4/   10] loss: 0.03147083\n",
      "[49,     6/   10] loss: 0.08502837\n",
      "[49,     8/   10] loss: 0.00849546\n",
      "Asdf\n",
      "[50,     2/   10] loss: 0.03198233\n",
      "[50,     4/   10] loss: 0.09044448\n",
      "[50,     6/   10] loss: 0.04748514\n",
      "[50,     8/   10] loss: 0.02647969\n",
      "Asdf\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init()\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "data_len = len(data_loader)\n",
    "wandb.watch(net, log_freq=100)\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        try:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1 )% 2 == 0:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}/{data_len:5d}] loss: {running_loss :.8f}')\n",
    "                wandb.log({\"loss\": running_loss/5})\n",
    "                running_loss = 0.0\n",
    "        except:\n",
    "            print(\"Asdf\")\n",
    "        \n",
    "    torch.save(net.state_dict(), \"model-v5.ckpt\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-bf325af22400>:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = torch.nn.functional.softmax(outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "Accuracy of the network on the 10000 test images:  100.00000000 %\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"model-v5.ckpt\"))\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(test_data_loader, 0):\n",
    "        print(i)\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs = torch.nn.functional.softmax(outputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total: .8f} %')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
