{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-co-mod-gan.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcipolina/escher/blob/master/ML/Colab-co-mod-gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8IMr-6DmSb"
      },
      "source": [
        "# Colab-co-mod-gan\n",
        "\n",
        "Original repo: [zsyzzsoft/co-mod-gan](https://github.com/zsyzzsoft/co-mod-gan)\n",
        "\n",
        "My fork: [styler00dollar/Colab-co-mod-gan](https://github.com/styler00dollar/Colab-co-mod-gan)\n",
        "\n",
        "Original Colab\n",
        "\n",
        "https://github.com/styler00dollar/Colab-co-mod-gan/blob/master/Colab-co-mod-gan.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRlqyRpO2fai"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdEJOZpC1Dg"
      },
      "source": [
        "# @title install\n",
        "\n",
        "!git clone https://github.com/zsyzzsoft/co-mod-gan\n",
        "#!git clone styler00dollar/Colab-co-mod-gan\n",
        "# tensorflow 1.15 to avoid tensorflow.python.framework.errors_impl.NotFoundError\n",
        "!pip install tensorflow==1.15\n",
        "%cd /content/co-mod-gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Efdn1cL88b9"
      },
      "source": [
        "# Testing\n",
        "\n",
        "Just place ``/content/input.png`` and ``/content/mask.png``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO2SkgBIHV_I"
      },
      "source": [
        "#@title download pretrain\n",
        "!gdown --id 1dJa3DRWIkx6Ebr8Sc0v1FdvWf6wkd010 # co-mod-gan-places2-050000.pkl\n",
        "#!gdown --id 1b3XxfAmJ9k2vd73j-3nPMr_lvNMQOFGE # co-mod-gan-ffhq-9-025000.pkl\n",
        "#!gdown --id 1M2dSxlJnCFNM6LblpB2nQCnaimgwaaKu # co-mod-gan-ffhq-10-025000.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload image and save name\n",
        " This is a little bit slower than just drag and drop - the only advantage is the name saving"
      ],
      "metadata": {
        "id": "fG99T5EjeCRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Get the name of uploaded image:\n",
        "for key in uploaded.keys():\n",
        "  uploaded_image = key"
      ],
      "metadata": {
        "id": "WvIrdSCKeNm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_image"
      ],
      "metadata": {
        "id": "ua5fsYLreiff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mask drawing code"
      ],
      "metadata": {
        "id": "MTO8223mdVTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  background-color: #4CAF50;\n",
        "  border: none;\n",
        "  color: white;\n",
        "  padding: 15px 32px;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  display: inline-block;\n",
        "  font-size: 16px;\n",
        "  margin: 4px 2px;\n",
        "  cursor: pointer;\n",
        "}\n",
        "</style>\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "\n",
        "<button class=\"button\">Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(imgm, filename='mask.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n"
      ],
      "metadata": {
        "id": "UTD9kg1WdiOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = 6"
      ],
      "metadata": {
        "id": "je8UaAZHdpdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64, os\n",
        "from base64 import b64decode\n",
        "#import cv2\n",
        "#convert to np array\n",
        "img = cv2.imread(uploaded_image)\n",
        "image64 = base64.b64encode(open(uploaded_image, 'rb').read()) #encoding images as text, this is a trick to manipulate the image better.\n",
        "image64 = image64.decode('utf-8')\n",
        "\n",
        "pencil_width = (width/100)*img.shape[1]  #sets width of brush\n",
        "draw(image64, w=img.shape[1], h=img.shape[0], line_width=pencil_width)\n",
        "\n",
        "#Save the masked image and convert the mask\n",
        "import matplotlib.pyplot as plt #it uses this garbage to read images and convert to arrays, instead of CV2, wrong choice of library\n",
        "with_mask = np.array(plt.imread(\"mask.png\")[:,:,:3])\n",
        "mask = (with_mask[:,:,0]==1)*(with_mask[:,:,1]==0)*(with_mask[:,:,2]==0)\n",
        "plt.imsave(\"mask.png\",mask, cmap='gray') #save mask"
      ],
      "metadata": {
        "id": "e9xKy4c5d9ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resize and convert images if needed"
      ],
      "metadata": {
        "id": "yxtpYdQMdX2R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGyKCHF53NjW"
      },
      "source": [
        "\n",
        "#@title (optional) read / write / resize file with opencv / invert mask\n",
        "#@markdown You need masks where ``white = original`` and ``black = inpaint``. Both images are rgb and have the needed dimensions.\n",
        "import cv2\n",
        "\n",
        "input_name = uploaded_image\n",
        "\n",
        "path_image = '/content/co-mod-gan/'  + input_name\n",
        "path_mask = '/content/co-mod-gan/' + 'mask.png'\n",
        "image = cv2.imread(path_image)\n",
        "image = cv2.resize(image, (512,512), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_image, image)\n",
        "\n",
        "image = cv2.imread(path_mask)\n",
        "image = 255-image\n",
        "image = cv2.resize(image, (512,512), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK mask color AND APPLY THIS ONLY IF NEEDED\n",
        "\n",
        "# ***** mask color inversion ***************************************************************************\n",
        "# The part of the image that has to be predicted by the model should be in black and the rest in white\n",
        "# The code above inverts the colors of the mask!\n",
        "src = '/content/co-mod-gan'\n",
        "#convert mask\n",
        "img = cv2.imread(src + 'input.png') # bitwise function needs img as array # use previously saved name    \n",
        "cv2.imwrite(src + 'mask.png', cv2.bitwise_not(img)) #operations are not done -in place - we need to go back from array to image"
      ],
      "metadata": {
        "id": "1DLPl1lCsyOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "#!gdown --id 1YbSxWraGrQzD7UVOyPF95FCgRz_H03uD # ours\n",
        "!gdown --id 1dJa3DRWIkx6Ebr8Sc0v1FdvWf6wkd010 #places2\n"
      ],
      "metadata": {
        "id": "8ixqm6bjuUE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Gray to RGB - CoModGans takes RGB channels\n",
        "#I've just used this online tool\n",
        "#https://pinetools.com/change-image-brightness\n",
        "\n",
        "#### ACTUALLY\n",
        "#The best way to make it work is to paste my image on top of the example img\n",
        "# otherwise it keeps throwing dimensions error.. as it is missing channels data"
      ],
      "metadata": {
        "id": "OMyFglATwGw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "LsV87gvyBXpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "# change name of input and mask files\n",
        "\n",
        "%cd /content/co-mod-gan\n",
        "!python run_generator.py -c /content/co-mod-gan/co-mod-gan-places2-050000.pkl -i /content/co-mod-gan/Ecce_Homo.png -m /content/co-mod-gan/mask.png -o /content/output.png\n",
        "\n",
        "print('DONE')\n",
        "\n",
        "files.download('/content/output.png') "
      ],
      "metadata": {
        "id": "Zp920a2nta15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN0z2dDgDHN-"
      },
      "source": [
        "'''\n",
        "%cd /content/co-mod-gan\n",
        "!python run_generator.py -c /content/network-snapshot-050060.pkl -i /content/co-mod-gan/imgs/example_image.jpg -m /content/co-mod-gan/imgs/example_mask.jpg -o /content/output.png\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTZriM0j9AER"
      },
      "source": [
        "# Training\n",
        "\n",
        "Warnings: Free colab does not have enough RAM. You need Colab Pro with 25GB RAM. Needs ~13GB RAM. Also needs ~10GB VRAM.\n",
        "\n",
        "Training can also crash, because of:\n",
        "```  \n",
        "File \"/content/co-mod-gan/metrics/inception_discriminative_score.py\", line 30, in _evaluate\n",
        "    inception = misc.load_pkl('https://drive.google.com/uc?id=1MzTY44rLToO5APn8TZmfR7_ENSe5aZUn') # inception_v3_features.pkl\n",
        "  File \"/content/co-mod-gan/training/misc.py\", line 29, in load_pkl\n",
        "    with open_file_or_url(file_or_url) as file:\n",
        "  File \"/content/co-mod-gan/training/misc.py\", line 25, in open_file_or_url\n",
        "    return dnnlib.util.open_url(file_or_url, cache_dir='.stylegan2-cache')\n",
        "  File \"/content/co-mod-gan/dnnlib/util.py\", line 383, in open_url\n",
        "    raise IOError(\"Google Drive download quota exceeded -- please try again later\")\n",
        "OSError: Google Drive download quota exceeded -- please try again later\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRnY3QOk9JsG"
      },
      "source": [
        "%cd /content/co-mod-gan/dataset_tools\n",
        "!python create_from_images.py --tfrecord-dir /content/tfrecord_dir --val-image-dir /content/val --train-image-dir /content/train --resolution 512 --num-channels 3 --num-processes 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riL8GVV_5lao"
      },
      "source": [
        "%cd /content/co-mod-gan\n",
        "# Example: /content/tfrecord_dir/tfrecord_dir-r09.tfrecords\n",
        "!python run_training.py --data-dir=/content/ --dataset=tfrecord_dir --metrics=ids10k --mirror-augment True --num-gpus=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}