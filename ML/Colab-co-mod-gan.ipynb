{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-co-mod-gan.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcipolina/escher/blob/master/ML/Colab-co-mod-gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO8IMr-6DmSb"
      },
      "source": [
        "# Colab-co-mod-gan\n",
        "\n",
        "Original repo: [zsyzzsoft/co-mod-gan](https://github.com/zsyzzsoft/co-mod-gan)\n",
        "\n",
        "My fork: [styler00dollar/Colab-co-mod-gan](https://github.com/styler00dollar/Colab-co-mod-gan)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRlqyRpO2fai"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKdEJOZpC1Dg"
      },
      "source": [
        "# @title install\n",
        "\n",
        "!git clone https://github.com/zsyzzsoft/co-mod-gan\n",
        "#!git clone styler00dollar/Colab-co-mod-gan\n",
        "# tensorflow 1.15 to avoid tensorflow.python.framework.errors_impl.NotFoundError\n",
        "!pip install tensorflow==1.15\n",
        "%cd /content/co-mod-gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Efdn1cL88b9"
      },
      "source": [
        "# Testing\n",
        "\n",
        "Just place ``/content/input.png`` and ``/content/mask.png``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO2SkgBIHV_I"
      },
      "source": [
        "#@title download pretrain\n",
        "!gdown --id 1dJa3DRWIkx6Ebr8Sc0v1FdvWf6wkd010 # co-mod-gan-places2-050000.pkl\n",
        "#!gdown --id 1b3XxfAmJ9k2vd73j-3nPMr_lvNMQOFGE # co-mod-gan-ffhq-9-025000.pkl\n",
        "#!gdown --id 1M2dSxlJnCFNM6LblpB2nQCnaimgwaaKu # co-mod-gan-ffhq-10-025000.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGyKCHF53NjW"
      },
      "source": [
        "#@title (optional) read / write / resize file with opencv / invert mask\n",
        "#@markdown You need masks where ``white = original`` and ``black = inpaint``. Both images are rgb and have the needed dimensions.\n",
        "import cv2\n",
        "path_image = '/content/input.png'\n",
        "path_mask = '/content/mask.png'\n",
        "image = cv2.imread(path_image)\n",
        "image = cv2.resize(image, (512,512), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_image, image)\n",
        "\n",
        "image = cv2.imread(path_mask)\n",
        "image = 255-image\n",
        "image = cv2.resize(image, (512,512), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OMyFglATwGw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "#!gdown --id 1YbSxWraGrQzD7UVOyPF95FCgRz_H03uD # ours\n",
        "!gdown --id 1dJa3DRWIkx6Ebr8Sc0v1FdvWf6wkd010 #places2\n"
      ],
      "metadata": {
        "id": "8ixqm6bjuUE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/co-mod-gan\n",
        "!python run_generator.py -c /content/co-mod-gan/co-mod-gan-places2-050000.pkl -i /content/co-mod-gan/imgs/example_image.jpg -m /content/co-mod-gan/imgs/example_mask.jpg -o /content/output.png"
      ],
      "metadata": {
        "id": "Zp920a2nta15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN0z2dDgDHN-"
      },
      "source": [
        "'''\n",
        "%cd /content/co-mod-gan\n",
        "!python run_generator.py -c /content/network-snapshot-050060.pkl -i /content/co-mod-gan/imgs/example_image.jpg -m /content/co-mod-gan/imgs/example_mask.jpg -o /content/output.png\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTZriM0j9AER"
      },
      "source": [
        "# Training\n",
        "\n",
        "Warnings: Free colab does not have enough RAM. You need Colab Pro with 25GB RAM. Needs ~13GB RAM. Also needs ~10GB VRAM.\n",
        "\n",
        "Training can also crash, because of:\n",
        "```  \n",
        "File \"/content/co-mod-gan/metrics/inception_discriminative_score.py\", line 30, in _evaluate\n",
        "    inception = misc.load_pkl('https://drive.google.com/uc?id=1MzTY44rLToO5APn8TZmfR7_ENSe5aZUn') # inception_v3_features.pkl\n",
        "  File \"/content/co-mod-gan/training/misc.py\", line 29, in load_pkl\n",
        "    with open_file_or_url(file_or_url) as file:\n",
        "  File \"/content/co-mod-gan/training/misc.py\", line 25, in open_file_or_url\n",
        "    return dnnlib.util.open_url(file_or_url, cache_dir='.stylegan2-cache')\n",
        "  File \"/content/co-mod-gan/dnnlib/util.py\", line 383, in open_url\n",
        "    raise IOError(\"Google Drive download quota exceeded -- please try again later\")\n",
        "OSError: Google Drive download quota exceeded -- please try again later\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRnY3QOk9JsG"
      },
      "source": [
        "%cd /content/co-mod-gan/dataset_tools\n",
        "!python create_from_images.py --tfrecord-dir /content/tfrecord_dir --val-image-dir /content/val --train-image-dir /content/train --resolution 512 --num-channels 3 --num-processes 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riL8GVV_5lao"
      },
      "source": [
        "%cd /content/co-mod-gan\n",
        "# Example: /content/tfrecord_dir/tfrecord_dir-r09.tfrecords\n",
        "!python run_training.py --data-dir=/content/ --dataset=tfrecord_dir --metrics=ids10k --mirror-augment True --num-gpus=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}