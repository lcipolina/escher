{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClipReranker.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcipolina/escher/blob/master/Img_Class/ClipReranker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colab version of this repo\n",
        "\n",
        "https://github.com/mehdidc/clip_rerank\n",
        "\n",
        "Thanks to @pbaylies and @afiaka87 and @alstroemeria313"
      ],
      "metadata": {
        "id": "GDP4-YxTMzuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COwIhTu6Lbv1",
        "outputId": "b3687791-8a55-48f5-8ba3-826a43c460e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 212 (delta 19), reused 24 (delta 9), pack-reused 168\u001b[K\n",
            "Receiving objects: 100% (212/212), 11.48 MiB | 23.14 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n",
            "Obtaining file:///content/CLIP\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Installing collected packages: ftfy, clip\n",
            "  Running setup.py develop for clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/openai/CLIP && cd CLIP && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clize --quiet"
      ],
      "metadata": {
        "id": "1EjIlB_ELdRh",
        "outputId": "88b93b34-0be5-4888-b3a0-10afa336eaf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 71 kB 85 kB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnmigXxWwkRO",
        "outputId": "d6054888-0b77-4b9a-a44c-84bf0211b43a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "from clize import run\n",
        "import torch\n",
        "from CLIP import clip\n",
        "from PIL import Image\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "9tRyeIPaLgHl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the images file\n",
        "url = \"https://drive.google.com/file/d/1BPsYLdfE9TPXTsx05pfS72w0uyzzKoHu/view?usp=sharing\"\n",
        "output = \"a.zip\"\n",
        "gdown.download(url, output, quiet=False, fuzzy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "EciQ5MISwsOv",
        "outputId": "52056f6e-0bfb-46a6-ef1c-fbada6019ac7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BPsYLdfE9TPXTsx05pfS72w0uyzzKoHu\n",
            "To: /content/a.zip\n",
            "100%|██████████| 35.3M/35.3M [00:00<00:00, 48.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the discriminator's weights\n",
        "url = \"https://drive.google.com/file/d/1cBFlNhbnkLQ0_sOM10OcV1Jtd5wwxUOr/view?usp=sharing\"\n",
        "output = \"model.ckpt\"\n",
        "gdown.download(url, output, quiet=False, fuzzy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "VxpcyNvv4-Lz",
        "outputId": "55822ad6-2e38-43f3-e8d4-480fcfd7cf82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cBFlNhbnkLQ0_sOM10OcV1Jtd5wwxUOr\n",
            "To: /content/model.ckpt\n",
            "100%|██████████| 9.80M/9.80M [00:00<00:00, 215MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip a.zip -d a"
      ],
      "metadata": {
        "id": "qkQ70tO4rXUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_feature_size = 118, batch_size = 1):\n",
        "        \n",
        "        super(Discriminator, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3)\n",
        "        self.bn1 = nn.BatchNorm2d(64, affine=False)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
        "        self.bn2 = nn.BatchNorm2d(128, affine=False)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3)\n",
        "        self.bn3 = nn.BatchNorm2d(256, affine=False)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3)\n",
        "        self.bn4 = nn.BatchNorm2d(512, affine=False)\n",
        "        self.conv5 = nn.Conv2d(512, 1, 3)\n",
        "        self.fc1 = nn.Linear(in_feature_size * in_feature_size , 64)\n",
        "        self.fc2 = nn.Linear(64, 8)\n",
        "        self.fc3 = nn.Linear(8, 2)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.conv5(x)\n",
        "        x = x.view(1, -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "device = \"cuda\"\n",
        "net = Discriminator()\n",
        "net = nn.DataParallel(net, device_ids=[0])\n",
        "net.load_state_dict(torch.load(\"model.ckpt\"))\n",
        "net.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgpCu-Bj45C8",
        "outputId": "197f17cf-8131-4c0c-c7e8-d24f6d19e451"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): Discriminator(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "    (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
              "    (conv5): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (fc1): Linear(in_features=13924, out_features=64, bias=True)\n",
              "    (fc2): Linear(in_features=64, out_features=8, bias=True)\n",
              "    (fc3): Linear(in_features=8, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.Resize([128, 128]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
        "            transforms.RandomHorizontalFlip(), # Flip the data horizontally\n",
        "            #TODO if it is needed, add the random crop\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.5), std=(0.5))\n",
        "        ])\n"
      ],
      "metadata": {
        "id": "artRc0UR5kTa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the CLIP score\n",
        "\n",
        "def main(pattern, text=\"a gallery with arches wooden windows and arcades and floors with tiles escher\", target_folder=\"reranked\", top:int=None):\n",
        "    device = \"cuda\"\n",
        "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "    paths = glob(pattern, recursive = True)\n",
        "    score = {}\n",
        "    score_good = {}\n",
        "    score_bad = {} \n",
        "    actual = []\n",
        "    predicted = []\n",
        "    for path in paths:\n",
        "        image = preprocess(Image.open(path)).unsqueeze(0).to(device)\n",
        "        image_disc =  torch.unsqueeze(transform(Image.open(path)), 0)\n",
        "        text = \"a gallery with arches wooden windows and arcades and floors with tiles escher\"\n",
        "        text = clip.tokenize([text]).to(device)\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(image)\n",
        "            text_features = model.encode_text(text)\n",
        "            logits_per_image, logits_pertext = model(image, text)\n",
        "            logits_disc = torch.nn.functional.softmax(net(image_disc))\n",
        "            index = torch.argmax(logits_disc).item()\n",
        "            if \"bad\" in path.lower():\n",
        "              actual.append(0)\n",
        "            else:\n",
        "              actual.append(1)\n",
        "\n",
        "            predicted.append(index)\n",
        "            if index == 0:\n",
        "              score_bad[path] = logits_per_image.item()\n",
        "            else:\n",
        "              score_good[path] = logits_per_image.item()\n",
        "            score[path] =  logits_per_image.item()\n",
        "            print(path, score[path])\n",
        "    paths = sorted(paths, key=lambda f:-score[f])\n",
        "    if top:\n",
        "        paths = paths[0:top]\n",
        "    os.makedirs(target_folder, exist_ok=True)\n",
        "    for i, path in enumerate(paths):\n",
        "        out_path = os.path.join(target_folder, f\"{i:010d}.png\")\n",
        "        Image.open(path).save(out_path)\n",
        "        \n",
        "    return score, score_bad, score_good, actual, predicted\n",
        "#if name == \"main\":\n",
        "#    run(main)"
      ],
      "metadata": {
        "id": "wUgFe8GQLkIh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score, score_bad, score_good, actual, predicted = main('./a/**/*.png')"
      ],
      "metadata": {
        "id": "It-4z4_OMMdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate stats\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def find_stats(score, title):\n",
        "  scores_raw = np.array(list(score.values()))\n",
        "  print(title)\n",
        "  print(f'Mean: {np.mean(scores_raw)}')\n",
        "  print(f'Median: {np.median(scores_raw)}')\n",
        "  print(f'Std_Dev: {np.std(scores_raw)}')\n",
        " \n",
        "\n",
        "find_stats(score, \"Total Stats\")\n",
        "find_stats(score_good, \"Stats Good Images\")\n",
        "find_stats(score_bad, \"Stats bad images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE2tPBv93kWO",
        "outputId": "13570579-f235-4900-98b3-b025f688bcf8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Stats\n",
            "Mean: 26.605922965116278\n",
            "Median: 26.6015625\n",
            "Variance: 0.8397965846549318\n",
            "Stats Good Images\n",
            "Mean: 26.554008152173914\n",
            "Median: 26.4609375\n",
            "Variance: 0.836828789638142\n",
            "Stats bad images\n",
            "Mean: 26.634695030120483\n",
            "Median: 26.625\n",
            "Variance: 0.8400562435730798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CGelLTQwUKI",
        "outputId": "7e8481da-7c17-4ba9-a0c9-06a58c7839b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf_matrix = confusion_matrix(actual, predicted, normalize = \"true\")\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "4G1m3mJZwGhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cm = pd.DataFrame(cf_matrix, index = [i for i in [\"Bad\", \"Good\"]],\n",
        "                  columns = [i for i in  [\"Bad\", \"Good\"]])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "metadata": {
        "id": "oGMLy3AK4ce-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "147e7565-4892-4a73-ccab-37a72194c746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc5b343890>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}